{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 5 - File Suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Np0plMPXRvoq"
   },
   "source": [
    "In this lesson, you will design an agent that can read the user goal, then use tools to evaluate\n",
    "available files to suggest relevant data sources.\n",
    "\n",
    "You'll learn:\n",
    "- how memory helps coordinate agent tasks\n",
    "- how tools can be be used to access the environment\n",
    "- how to trust, but verify inside of tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> ðŸ’» &nbsp; <b>To access the helper.py, neo4j_for_adk.py and tools.py files :</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"images/entire_solution.png\" width=\"500\">\n",
    "\n",
    "The File Suggestion agent is a tool-use agent that suggests files to use for import, based on the approved user goal from the previous lesson.\n",
    "\n",
    "\n",
    "- Input: `approved_user_goal`, a dictionary pairing a kind of graph with a description of the purpose of the graph.\n",
    "- Output: `approved_files`, a list of files that have been approved for import.\n",
    "- Tools: `get_approved_user_goal`, `list_import_files`, `sample_file`, `set_suggested_files`, `approve_suggested_files`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual import of needed libraries, loading of environment variables, and connection to Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For OpenAI support\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.tools import ToolContext\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "# For type hints\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "# Convenience libraries for working with Neo4j inside of Google ADK\n",
    "from neo4j_for_adk import graphdb, tool_success, tool_error\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.CRITICAL)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResponse(id='chatcmpl-CFRRaGCSMJ8yC6wU0cnozQzPk8b8w', created=1757796450, model='gpt-4o-2024-08-06', object='chat.completion', system_fingerprint='fp_ee1d74bde0', choices=[Choices(finish_reason='stop', index=0, message=Message(content=\"Yes, I'm ready! How can I assist you today?\", role='assistant', tool_calls=None, function_call=None, provider_specific_fields={'refusal': None}, annotations=[]), provider_specific_fields={})], usage=Usage(completion_tokens=13, prompt_tokens=11, total_tokens=24, completion_tokens_details=CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), prompt_tokens_details=PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)), service_tier=None)\n",
      "\n",
      "OpenAI is ready.\n"
     ]
    }
   ],
   "source": [
    "# --- Define Model Constants for easier use ---\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "\n",
    "llm = LiteLlm(model=MODEL_GPT_4O)\n",
    "\n",
    "# Test LLM with a direct call\n",
    "print(llm.llm_client.completion(model=llm.model, messages=[{\"role\": \"user\", \"content\": \"Are you ready?\"}], tools=[]))\n",
    "\n",
    "print(\"\\nOpenAI is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Define the File Suggestion Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1. Agent Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "height": 404
   },
   "outputs": [],
   "source": [
    "file_suggestion_agent_instruction = \"\"\"\n",
    "You are a constructive critic AI reviewing a list of files. Your goal is to suggest relevant files\n",
    "for constructing a knowledge graph.\n",
    "\n",
    "**Task:**\n",
    "Review the file list for relevance to the kind of graph and description specified in the approved user goal. \n",
    "\n",
    "For any file that you're not sure about, use the 'sample_file' tool to get \n",
    "a better understanding of the file contents. \n",
    "\n",
    "Only consider structured data files like CSV or JSON.\n",
    "\n",
    "Prepare for the task:\n",
    "- use the 'get_approved_user_goal' tool to get the approved user goal\n",
    "\n",
    "Think carefully, repeating these steps until finished:\n",
    "1. list available files using the 'list_available_files' tool\n",
    "2. evaluate the relevance of each file, then record the list of suggested files using the 'set_suggested_files' tool\n",
    "3. use the 'get_suggested_files' tool to get the list of suggested files\n",
    "4. ask the user to approve the set of suggested files\n",
    "5. If the user has feedback, go back to step 1 with that feedback in mind\n",
    "6. If approved, use the 'approve_suggested_files' tool to record the approval\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 Tool Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "# import tools defined in previous lesson\n",
    "from tools import get_approved_user_goal\n",
    "from helper import get_neo4j_import_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** `neo4j` database has a directory called `import` where you can place `csv` files that you intend to import into your Neo4j database. `get_neo4j_import_dir` represents the path to the directory that is in-sync with the `import` directory of the Neo4j database (running in a sidecar container). This directory has the csv files that the agent will sample and the select the suggested files. \n",
    "\n",
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> ðŸ’» &nbsp; <b>To access the <code>csv</code> files :</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em>. Click on the home directory (small folder icon), you will find the csv files inside the <code>data</code> folder.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "height": 555
   },
   "outputs": [],
   "source": [
    "# Tool: List Import Files\n",
    "\n",
    "# this constant will be used as the key for storing the file list in the tool context state\n",
    "ALL_AVAILABLE_FILES = \"all_available_files\"\n",
    "\n",
    "def list_available_files(tool_context:ToolContext) -> dict:\n",
    "    f\"\"\"Lists files available for knowledge graph construction.\n",
    "    All files are relative to the import directory.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing metadata about the content.\n",
    "                Includes a 'status' key ('success' or 'error').\n",
    "                If 'success', includes a {ALL_AVAILABLE_FILES} key with list of file names.\n",
    "                If 'error', includes an 'error_message' key.\n",
    "                The 'error_message' may have instructions about how to handle the error.\n",
    "    \"\"\"\n",
    "    # get the import dir using the helper function\n",
    "    import_dir = Path(get_neo4j_import_dir())\n",
    "\n",
    "    # get a list of relative file names, so files must be rooted at the import dir\n",
    "    file_names = [str(x.relative_to(import_dir)) \n",
    "                 for x in import_dir.rglob(\"*\") \n",
    "                 if x.is_file()]\n",
    "\n",
    "    # save the list to state so we can inspect it later\n",
    "    tool_context.state[ALL_AVAILABLE_FILES] = file_names\n",
    "\n",
    "    return tool_success(ALL_AVAILABLE_FILES, file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "height": 725
   },
   "outputs": [],
   "source": [
    "# Tool: Sample File\n",
    "# This is a simple file reading tool that only works on files from the import directory\n",
    "def sample_file(file_path: str, tool_context: ToolContext) -> dict:\n",
    "    \"\"\"Samples a file by reading its content as text.\n",
    "    \n",
    "    Treats any file as text and reads up to a maximum of 100 lines.\n",
    "    \n",
    "    Args:\n",
    "      file_path: file to sample, relative to the import directory\n",
    "      \n",
    "    Returns:\n",
    "        dict: A dictionary containing metadata about the content,\n",
    "            along with a sampling of the file.\n",
    "            Includes a 'status' key ('success' or 'error').\n",
    "            If 'success', includes a 'content' key with textual file content.\n",
    "            If 'error', includes an 'error_message' key.\n",
    "            The 'error_message' may have instructions about how to handle the error.\n",
    "    \"\"\"\n",
    "    # Trust, but verify. The agent may invent absolute file paths. \n",
    "    if Path(file_path).is_absolute():\n",
    "        return tool_error(\"File path must be relative to the import directory. Make sure the file is from the list of available files.\")\n",
    "    \n",
    "    import_dir = Path(get_neo4j_import_dir())\n",
    "\n",
    "    # create the full path by extending from the import_dir\n",
    "    full_path_to_file = import_dir / file_path\n",
    "    \n",
    "    # of course, _that_ may not exist\n",
    "    if not full_path_to_file.exists():\n",
    "        return tool_error(f\"File does not exist in import directory. Make sure {file_path} is from the list of available files.\")\n",
    "    \n",
    "    try:\n",
    "        # Treat all files as text\n",
    "        with open(full_path_to_file, 'r', encoding='utf-8') as file:\n",
    "            # Read up to 100 lines\n",
    "            lines = list(islice(file, 100))\n",
    "            content = ''.join(lines)\n",
    "            return tool_success(\"content\", content)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return tool_error(f\"Error reading or processing file {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "height": 540
   },
   "outputs": [],
   "source": [
    "# Tool: Set/Get suggested files\n",
    "SUGGESTED_FILES = \"suggested_files\"\n",
    "\n",
    "def set_suggested_files(suggest_files:List[str], tool_context:ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"Set the suggested files to be used for data import.\n",
    "\n",
    "    Args:\n",
    "        suggest_files (List[str]): List of file paths to suggest\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: A dictionary containing metadata about the content.\n",
    "                Includes a 'status' key ('success' or 'error').\n",
    "                If 'success', includes a {SUGGESTED_FILES} key with list of file names.\n",
    "                If 'error', includes an 'error_message' key.\n",
    "                The 'error_message' may have instructions about how to handle the error.\n",
    "    \"\"\"\n",
    "    tool_context.state[SUGGESTED_FILES] = suggest_files\n",
    "    return tool_success(SUGGESTED_FILES, suggest_files)\n",
    "\n",
    "# Helps encourage the LLM to first set the suggested files.\n",
    "# This is an important strategy for maintaining consistency through defined values.\n",
    "def get_suggested_files(tool_context:ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"Get the files to be used for data import.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: A dictionary containing metadata about the content.\n",
    "                Includes a 'status' key ('success' or 'error').\n",
    "                If 'success', includes a {SUGGESTED_FILES} key with list of file names.\n",
    "                If 'error', includes an 'error_message' key.\n",
    "    \"\"\"\n",
    "    return tool_success(SUGGESTED_FILES, tool_context.state[SUGGESTED_FILES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "height": 268
   },
   "outputs": [],
   "source": [
    "# Tool: Approve Suggested Files\n",
    "# Just like the previous lesson, you'll define a tool which\n",
    "# accepts no arguments and can sanity check before approving.\n",
    "APPROVED_FILES = \"approved_files\"\n",
    "\n",
    "def approve_suggested_files(tool_context:ToolContext) -> Dict[str, Any]:\n",
    "    \"\"\"Approves the {SUGGESTED_FILES} in state for further processing as {APPROVED_FILES}.\n",
    "    \n",
    "    If {SUGGESTED_FILES} is not in state, return an error.\n",
    "    \"\"\"\n",
    "    if SUGGESTED_FILES not in tool_context.state:\n",
    "        return tool_error(\"Current files have not been set. Take no action other than to inform user.\")\n",
    "\n",
    "    tool_context.state[APPROVED_FILES] = tool_context.state[SUGGESTED_FILES]\n",
    "    return tool_success(APPROVED_FILES, tool_context.state[APPROVED_FILES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "# List of tools for the file suggestion agent\n",
    "file_suggestion_agent_tools = [get_approved_user_goal, list_available_files, sample_file, \n",
    "    set_suggested_files, get_suggested_files,\n",
    "    approve_suggested_files\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3. Agent Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'file_suggestion_agent_v1' created.\n"
     ]
    }
   ],
   "source": [
    "# Finally, construct the agent\n",
    "\n",
    "file_suggestion_agent = Agent(\n",
    "    name=\"file_suggestion_agent_v1\",\n",
    "    model=llm, # defined earlier in a variable\n",
    "    description=\"Helps the user select files to import.\",\n",
    "    instruction=file_suggestion_agent_instruction,\n",
    "    tools=file_suggestion_agent_tools,\n",
    ")\n",
    "\n",
    "print(f\"Agent '{file_suggestion_agent.name}' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zKGVwRkSduA"
   },
   "source": [
    "## 5.4. Interact with the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by LLMs can vary with each execution due to their stochastic nature. Your results might differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "height": 166,
    "id": "yZJr8lbkSebH"
   },
   "outputs": [],
   "source": [
    "from helper import make_agent_caller\n",
    "\n",
    "file_suggestion_caller = await make_agent_caller(file_suggestion_agent, {\n",
    "    \"approved_user_goal\": {\n",
    "        \"kind_of_graph\": \"supply chain analysis\",\n",
    "        \"description\": \"A multi-level bill of materials for manufactured products, useful for root cause analysis..\"\n",
    "    }   \n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: What files can we use for import?\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run the Initial Conversation\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# nudge the agent to look for files. in the full system, this will be the natural next step\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m file_suggestion_caller.call(\u001b[33m\"\u001b[39m\u001b[33mWhat files can we use for import?\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m session_end = \u001b[38;5;28;01mawait\u001b[39;00m file_suggestion_caller.get_session()\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/deeplearning.ai-course/Agentic Knowledge Graph Construction/L6/helper.py:55\u001b[39m, in \u001b[36mAgentCaller.call\u001b[39m\u001b[34m(self, query, verbose)\u001b[39m\n\u001b[32m     51\u001b[39m final_response_text = \u001b[33m\"\u001b[39m\u001b[33mAgent did not produce a final response.\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;66;03m# Default\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Key Concept: run_async executes the agent logic and yields Events.\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# We iterate through events to find the final answer.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.runner.run_async(user_id=\u001b[38;5;28mself\u001b[39m.user_id, session_id=\u001b[38;5;28mself\u001b[39m.session_id, new_message=content):\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# You can uncomment the line below to see *all* events during execution\u001b[39;00m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[32m     58\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  [Event] Author: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent.author\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(event).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Final: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent.is_final_response()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Content: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mevent.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/deeplearning.ai-course/.venv/lib/python3.11/site-packages/google/adk/runners.py:203\u001b[39m, in \u001b[36mRunner.run_async\u001b[39m\u001b[34m(self, user_id, session_id, new_message, run_config)\u001b[39m\n\u001b[32m    195\u001b[39m   \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._append_new_message_to_session(\n\u001b[32m    196\u001b[39m       session,\n\u001b[32m    197\u001b[39m       new_message,\n\u001b[32m    198\u001b[39m       invocation_context,\n\u001b[32m    199\u001b[39m       run_config.save_input_blobs_as_artifacts,\n\u001b[32m    200\u001b[39m   )\n\u001b[32m    202\u001b[39m invocation_context.agent = \u001b[38;5;28mself\u001b[39m._find_agent_to_run(session, root_agent)\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m invocation_context.agent.run_async(invocation_context):\n\u001b[32m    204\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event.partial:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.session_service.append_event(session=session, event=event)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/deeplearning.ai-course/.venv/lib/python3.11/site-packages/google/adk/agents/base_agent.py:147\u001b[39m, in \u001b[36mBaseAgent.run_async\u001b[39m\u001b[34m(self, parent_context)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n\u001b[32m    145\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_async_impl(ctx):\n\u001b[32m    148\u001b[39m   \u001b[38;5;28;01myield\u001b[39;00m event\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ctx.end_invocation:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/deeplearning.ai-course/.venv/lib/python3.11/site-packages/google/adk/agents/llm_agent.py:275\u001b[39m, in \u001b[36mLlmAgent._run_async_impl\u001b[39m\u001b[34m(self, ctx)\u001b[39m\n\u001b[32m    271\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_async_impl\u001b[39m(\n\u001b[32m    273\u001b[39m     \u001b[38;5;28mself\u001b[39m, ctx: InvocationContext\n\u001b[32m    274\u001b[39m ) -> AsyncGenerator[Event, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._llm_flow.run_async(ctx):\n\u001b[32m    276\u001b[39m     \u001b[38;5;28mself\u001b[39m.__maybe_save_output_to_state(event)\n\u001b[32m    277\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/deeplearning.ai-course/.venv/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:282\u001b[39m, in \u001b[36mBaseLlmFlow.run_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    281\u001b[39m   last_event = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._run_one_step_async(invocation_context):\n\u001b[32m    283\u001b[39m     last_event = event\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/deeplearning.ai-course/.venv/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:318\u001b[39m, in \u001b[36mBaseLlmFlow._run_one_step_async\u001b[39m\u001b[34m(self, invocation_context)\u001b[39m\n\u001b[32m    308\u001b[39m model_response_event = Event(\n\u001b[32m    309\u001b[39m     \u001b[38;5;28mid\u001b[39m=Event.new_id(),\n\u001b[32m    310\u001b[39m     invocation_id=invocation_context.invocation_id,\n\u001b[32m    311\u001b[39m     author=invocation_context.agent.name,\n\u001b[32m    312\u001b[39m     branch=invocation_context.branch,\n\u001b[32m    313\u001b[39m )\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m llm_response \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_llm_async(\n\u001b[32m    315\u001b[39m     invocation_context, llm_request, model_response_event\n\u001b[32m    316\u001b[39m ):\n\u001b[32m    317\u001b[39m   \u001b[38;5;66;03m# Postprocess after calling the LLM.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._postprocess_async(\n\u001b[32m    319\u001b[39m       invocation_context, llm_request, llm_response, model_response_event\n\u001b[32m    320\u001b[39m   ):\n\u001b[32m    321\u001b[39m     \u001b[38;5;66;03m# Update the mutable event id to avoid conflict\u001b[39;00m\n\u001b[32m    322\u001b[39m     model_response_event.id = Event.new_id()\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/deeplearning.ai-course/.venv/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:390\u001b[39m, in \u001b[36mBaseLlmFlow._postprocess_async\u001b[39m\u001b[34m(self, invocation_context, llm_request, llm_response, model_response_event)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;66;03m# Handles function calls.\u001b[39;00m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_response_event.get_function_calls():\n\u001b[32m--> \u001b[39m\u001b[32m390\u001b[39m   \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._postprocess_handle_function_calls_async(\n\u001b[32m    391\u001b[39m       invocation_context, model_response_event, llm_request\n\u001b[32m    392\u001b[39m   ):\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m event\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/deeplearning.ai-course/.venv/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:465\u001b[39m, in \u001b[36mBaseLlmFlow._postprocess_handle_function_calls_async\u001b[39m\u001b[34m(self, invocation_context, function_call_event, llm_request)\u001b[39m\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_postprocess_handle_function_calls_async\u001b[39m(\n\u001b[32m    460\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    461\u001b[39m     invocation_context: InvocationContext,\n\u001b[32m    462\u001b[39m     function_call_event: Event,\n\u001b[32m    463\u001b[39m     llm_request: LlmRequest,\n\u001b[32m    464\u001b[39m ) -> AsyncGenerator[Event, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m function_response_event := \u001b[38;5;28;01mawait\u001b[39;00m functions.handle_function_calls_async(\n\u001b[32m    466\u001b[39m       invocation_context, function_call_event, llm_request.tools_dict\n\u001b[32m    467\u001b[39m   ):\n\u001b[32m    468\u001b[39m     auth_event = functions.generate_auth_event(\n\u001b[32m    469\u001b[39m         invocation_context, function_response_event\n\u001b[32m    470\u001b[39m     )\n\u001b[32m    471\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m auth_event:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/deeplearning.ai-course/.venv/lib/python3.11/site-packages/google/adk/flows/llm_flows/functions.py:168\u001b[39m, in \u001b[36mhandle_function_calls_async\u001b[39m\u001b[34m(invocation_context, function_call_event, tools_dict, filters)\u001b[39m\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_response:\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m   function_response = \u001b[38;5;28;01mawait\u001b[39;00m __call_tool_async(\n\u001b[32m    169\u001b[39m       tool, args=function_args, tool_context=tool_context\n\u001b[32m    170\u001b[39m   )\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m agent.canonical_after_tool_callbacks:\n\u001b[32m    173\u001b[39m   altered_function_response = callback(\n\u001b[32m    174\u001b[39m       tool=tool,\n\u001b[32m    175\u001b[39m       args=function_args,\n\u001b[32m    176\u001b[39m       tool_context=tool_context,\n\u001b[32m    177\u001b[39m       tool_response=function_response,\n\u001b[32m    178\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/deeplearning.ai-course/.venv/lib/python3.11/site-packages/google/adk/flows/llm_flows/functions.py:449\u001b[39m, in \u001b[36m__call_tool_async\u001b[39m\u001b[34m(tool, args, tool_context)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call_tool_async\u001b[39m(\n\u001b[32m    444\u001b[39m     tool: BaseTool,\n\u001b[32m    445\u001b[39m     args: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[32m    446\u001b[39m     tool_context: ToolContext,\n\u001b[32m    447\u001b[39m ) -> Any:\n\u001b[32m    448\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls the tool.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m tool.run_async(args=args, tool_context=tool_context)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/GitHub/deeplearning.ai-course/.venv/lib/python3.11/site-packages/google/adk/tools/function_tool.py:112\u001b[39m, in \u001b[36mFunctionTool.run_async\u001b[39m\u001b[34m(self, args, tool_context)\u001b[39m\n\u001b[32m    110\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.func(**args_to_call)\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs_to_call\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mlist_available_files\u001b[39m\u001b[34m(tool_context)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mLists files available for knowledge graph construction.\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33mAll files are relative to the import directory.\u001b[39m\n\u001b[32m      9\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     15\u001b[39m \u001b[33m            The \u001b[39m\u001b[33m'\u001b[39m\u001b[33merror_message\u001b[39m\u001b[33m'\u001b[39m\u001b[33m may have instructions about how to handle the error.\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# get the import dir using the helper function\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m import_dir = \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_neo4j_import_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# get a list of relative file names, so files must be rooted at the import dir\u001b[39;00m\n\u001b[32m     21\u001b[39m file_names = [\u001b[38;5;28mstr\u001b[39m(x.relative_to(import_dir)) \n\u001b[32m     22\u001b[39m              \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m import_dir.rglob(\u001b[33m\"\u001b[39m\u001b[33m*\u001b[39m\u001b[33m\"\u001b[39m) \n\u001b[32m     23\u001b[39m              \u001b[38;5;28;01mif\u001b[39;00m x.is_file()]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.8/lib/python3.11/pathlib.py:871\u001b[39m, in \u001b[36mPath.__new__\u001b[39m\u001b[34m(cls, *args, **kwargs)\u001b[39m\n\u001b[32m    869\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Path:\n\u001b[32m    870\u001b[39m     \u001b[38;5;28mcls\u001b[39m = WindowsPath \u001b[38;5;28;01mif\u001b[39;00m os.name == \u001b[33m'\u001b[39m\u001b[33mnt\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m PosixPath\n\u001b[32m--> \u001b[39m\u001b[32m871\u001b[39m \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_from_parts\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._flavour.is_supported:\n\u001b[32m    873\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot instantiate \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m on your system\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    874\u001b[39m                               % (\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m,))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.8/lib/python3.11/pathlib.py:509\u001b[39m, in \u001b[36mPurePath._from_parts\u001b[39m\u001b[34m(cls, args)\u001b[39m\n\u001b[32m    504\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_from_parts\u001b[39m(\u001b[38;5;28mcls\u001b[39m, args):\n\u001b[32m    506\u001b[39m     \u001b[38;5;66;03m# We need to call _parse_args on the instance, so as to get the\u001b[39;00m\n\u001b[32m    507\u001b[39m     \u001b[38;5;66;03m# right flavour.\u001b[39;00m\n\u001b[32m    508\u001b[39m     \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28mobject\u001b[39m.\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m     drv, root, parts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    510\u001b[39m     \u001b[38;5;28mself\u001b[39m._drv = drv\n\u001b[32m    511\u001b[39m     \u001b[38;5;28mself\u001b[39m._root = root\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.8/lib/python3.11/pathlib.py:493\u001b[39m, in \u001b[36mPurePath._parse_args\u001b[39m\u001b[34m(cls, args)\u001b[39m\n\u001b[32m    491\u001b[39m     parts += a._parts\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     a = os.fspath(a)\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    495\u001b[39m         \u001b[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001b[39;00m\n\u001b[32m    496\u001b[39m         parts.append(\u001b[38;5;28mstr\u001b[39m(a))\n",
      "\u001b[31mTypeError\u001b[39m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "# Run the Initial Conversation\n",
    "\n",
    "# nudge the agent to look for files. in the full system, this will be the natural next step\n",
    "await file_suggestion_caller.call(\"What files can we use for import?\")\n",
    "\n",
    "session_end = await file_suggestion_caller.get_session()\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "# expect that the agent has listed available files\n",
    "print(\"Available files: \", session_end.state[ALL_AVAILABLE_FILES])\n",
    "\n",
    "# the suggested files should be reasonable looking CSV files\n",
    "print(\"Suggested files: \", session_end.state[SUGGESTED_FILES])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look through the transcript, noticing the tool use and final message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agree with the file suggestions\n",
    "await file_suggestion_caller.call(\"Yes, let's do it\")\n",
    "\n",
    "session_end = await file_suggestion_caller.get_session()\n",
    "\n",
    "print(\"\\n---\\n\")\n",
    "\n",
    "print(\"Approved files: \", session_end.state[APPROVED_FILES])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xbUzAGvsmB2a"
   },
   "source": [
    "Congratulations\\! You've now setup the files suggestion agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5. Optional - Sequence diagram illustrating the workflow of  \"File Suggestion Agent\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/file_suggestions_sequence_diagram.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
